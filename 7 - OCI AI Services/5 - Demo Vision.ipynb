{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "742fade3",
   "metadata": {},
   "source": [
    "# Lesson: Using OCI Vision in the Console\n",
    "\n",
    "## Introduction\n",
    "Welcome to this lesson on **OCI Vision in the Oracle Cloud Console**.  \n",
    "In this session, we’ll explore how to use the **Vision service** directly from the Oracle Cloud Console to perform **image classification**, **object detection**, and understand how Vision AI processes and tags visual data.\n",
    "\n",
    "By the end of this lesson, you will know:\n",
    "- How to navigate to the OCI Vision console  \n",
    "- How to use **image classification** and **object detection**  \n",
    "- How OCI Vision detects text and objects within images  \n",
    "- How you can extend capabilities through **custom models**\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Navigating to OCI Vision\n",
    "We begin at the **Oracle Cloud Console homepage**.  \n",
    "\n",
    "To access the Vision service:\n",
    "1. Go to the **Menu**.\n",
    "2. Select **Analytics & AI**.\n",
    "3. Under **AI Services**, click **Vision**.\n",
    "\n",
    "This brings you to the **Vision homepage**, where you’ll find:\n",
    "- Links to **resources and documentation**\n",
    "- Access to **image analysis** features (classification and object detection)\n",
    "- Access to **Document AI**\n",
    "- Options for creating **custom models**\n",
    "\n",
    "Although the service supports creating and training your own models, we will focus on **image classification** and **object detection** for this demo.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2: Image Classification\n",
    "Click on **Image Classification** to begin.\n",
    "\n",
    "OCI Vision provides some **default sample images**.  \n",
    "Let’s start by analyzing one of them.\n",
    "\n",
    "After running the analysis, Vision automatically assigns **tags** (or labels) that describe the objects and features in the image.  \n",
    "For example, for an image of power lines, you might see tags like:\n",
    "- *Overhead power line*  \n",
    "- *Transmission tower*  \n",
    "- *Plant*  \n",
    "- *Sky*  \n",
    "- *Line*  \n",
    "\n",
    "The results appear accurate, showing that Vision successfully identifies and classifies the main features.\n",
    "\n",
    "Next, let’s upload a new image.  \n",
    "We drag and drop an image of **iconic London** directly from the desktop.  \n",
    "\n",
    "Vision analyzes it and returns tags such as:\n",
    "- *Skyscraper*  \n",
    "- *Water*  \n",
    "- *Building*  \n",
    "- *Bridge*  \n",
    "- *Boat*  \n",
    "\n",
    "These are all correct tags for this kind of urban scene, showing how effectively the model classifies visual content.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 3: Object Detection\n",
    "Now, select the **Object Detection** feature.\n",
    "\n",
    "Similar to before, the console offers **default images** to demonstrate detection.  \n",
    "This time, Vision doesn’t just classify the scene — it identifies **specific objects** and draws **bounding boxes** around them.\n",
    "\n",
    "For instance, in a street scene:\n",
    "- It detects a **car** in the foreground.  \n",
    "- Identifies a **bus** in the background.  \n",
    "- Detects **people** walking on the sidewalk.  \n",
    "- Even detects **partial vehicles**, such as a fraction of a car visible at the edge.\n",
    "\n",
    "These bounding boxes correspond to the actual detection data returned by the API.\n",
    "\n",
    "In addition to objects, **text detection** is also performed.  \n",
    "Vision highlights textual elements found in the image, such as:\n",
    "- **License plate numbers**  \n",
    "- **Logos** (e.g., the *Oracle* logo on a car)  \n",
    "- **Bus route signs**  \n",
    "- **Advertisements on vehicles**\n",
    "\n",
    "Interestingly, the service even detects small and distant text, demonstrating its precision and sensitivity.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 4: Testing with Different Images\n",
    "Next, we test a **low-resolution image** of a rooftop.  \n",
    "Vision accurately identifies a **person standing on the roof**, even though it is subtle and small in the frame.  \n",
    "\n",
    "However, it does **not detect unusual circular microwave antennas** on the same roof, since these are not part of the pretrained model categories.  \n",
    "You could, however, **build a custom model** to detect these specialized objects if needed.\n",
    "\n",
    "Finally, let’s look at another image — a group of **cyclists on a road**.  \n",
    "OCI Vision performs exceptionally well here:\n",
    "- It detects each **person**, even though they are **bent forward** and **facing away** from the camera.  \n",
    "- It detects that each person is **riding a bicycle**, showing **nested bounding boxes** for *person* and *bicycle*.  \n",
    "- It even identifies **bicycle wheels** as individual elements.\n",
    "\n",
    "There is no significant text in this image, though Vision highlights what appears to be a dash or marking on the cyclist’s clothing.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 5: Summary\n",
    "In this lesson, we explored **OCI Vision in the Console** and learned how to:\n",
    "- Navigate to the Vision service through **Analytics & AI**.  \n",
    "- Perform **Image Classification** and **Object Detection**.  \n",
    "- See how Vision identifies both **objects and text** within images.  \n",
    "- Understand how to extend detection through **custom model training**.\n",
    "\n",
    "OCI Vision offers an intuitive, powerful toolset for extracting structured insights from visual content — enabling developers, analysts, and data scientists to build AI-powered applications that “see” and interpret the world.\n",
    "\n",
    "**End of Lesson: Using OCI Vision in the Console**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
